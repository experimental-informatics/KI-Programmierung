{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://s14-eu5.startpage.com/cgi-bin/serveimage?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FvyyTpL8QKgc%2Fmaxresdefault.jpg&sp=4b3124cbd9f8e6bd8404f7f357a8c1c9&anticache=748406)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variablen setzen (strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As you yourself are changing you may also begin to change the way you spend your time. Instead of spending four hours each day watching television, you may now prefer to play the saxophone in a jazz band and to have fun working on your first novel. Instead of spending the weekends hanging out in the pub with your old buddies talking about football, you acquire new friends with whom you can discuss things that now seem to you to be of greater significance than sport. Together with some of these new friends, you set up a local chapter of an international non- profit to help draw attention to the plight of political prisoners. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "englisch = \"\"\"As you yourself are changing you may also begin to change the way you spend your time. Instead of spending four hours each day watching television, you may now prefer to play the saxophone in a jazz band and to have fun working on your first novel. Instead of spending the weekends hanging out in the pub with your old buddies talking about football, you acquire new friends with whom you can discuss things that now seem to you to be of greater significance than sport. Together with some of these new friends, you set up a local chapter of an international non- profit to help draw attention to the plight of political prisoners.\"\"\"\n",
    "print(englisch, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# tokenization mit Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'you', 'yourself', 'are', 'changing', 'you', 'may', 'also', 'begin', 'to', 'change', 'the', 'way', 'you', 'spend', 'your', 'time.', 'Instead', 'of', 'spending', 'four', 'hours', 'each', 'day', 'watching', 'television,', 'you', 'may', 'now', 'prefer', 'to', 'play', 'the', 'saxophone', 'in', 'a', 'jazz', 'band', 'and', 'to', 'have', 'fun', 'working', 'on', 'your', 'first', 'novel.', 'Instead', 'of', 'spending', 'the', 'weekends', 'hanging', 'out', 'in', 'the', 'pub', 'with', 'your', 'old', 'buddies', 'talking', 'about', 'football,', 'you', 'acquire', 'new', 'friends', 'with', 'whom', 'you', 'can', 'discuss', 'things', 'that', 'now', 'seem', 'to', 'you', 'to', 'be', 'of', 'greater', 'significance', 'than', 'sport.', 'Together', 'with', 'some', 'of', 'these', 'new', 'friends,', 'you', 'set', 'up', 'a', 'local', 'chapter', 'of', 'an', 'international', 'non-', 'profit', 'to', 'help', 'draw', 'attention', 'to', 'the', 'plight', 'of', 'political', 'prisoners.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitten mit python (whitespace):\n",
    "print(englisch.split(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# tokenization mit NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As you yourself are changing you may also begin to change the way you spend your time.', 'Instead of spending four hours each day watching television, you may now prefer to play the saxophone in a jazz band and to have fun working on your first novel.', 'Instead of spending the weekends hanging out in the pub with your old buddies talking about football, you acquire new friends with whom you can discuss things that now seem to you to be of greater significance than sport.', 'Together with some of these new friends, you set up a local chapter of an international non- profit to help draw attention to the plight of political prisoners.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokenized_text=sent_tokenize(englisch)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'you', 'yourself', 'are', 'changing', 'you', 'may', 'also', 'begin', 'to', 'change', 'the', 'way', 'you', 'spend', 'your', 'time', '.', 'Instead', 'of', 'spending', 'four', 'hours', 'each', 'day', 'watching', 'television', ',', 'you', 'may', 'now', 'prefer', 'to', 'play', 'the', 'saxophone', 'in', 'a', 'jazz', 'band', 'and', 'to', 'have', 'fun', 'working', 'on', 'your', 'first', 'novel', '.', 'Instead', 'of', 'spending', 'the', 'weekends', 'hanging', 'out', 'in', 'the', 'pub', 'with', 'your', 'old', 'buddies', 'talking', 'about', 'football', ',', 'you', 'acquire', 'new', 'friends', 'with', 'whom', 'you', 'can', 'discuss', 'things', 'that', 'now', 'seem', 'to', 'you', 'to', 'be', 'of', 'greater', 'significance', 'than', 'sport', '.', 'Together', 'with', 'some', 'of', 'these', 'new', 'friends', ',', 'you', 'set', 'up', 'a', 'local', 'chapter', 'of', 'an', 'international', 'non-', 'profit', 'to', 'help', 'draw', 'attention', 'to', 'the', 'plight', 'of', 'political', 'prisoners', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_word=word_tokenize(englisch)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stoppwörter** werden als Rauschen im Text betrachtet. Text kann Stoppwörter wie is, am, are, this, a, an, the, etc. enthalten.\n",
    "\n",
    "In NLTK - für das Entfernen von Stopwords müssen wir eine Liste von Stopwords erstellen und diese Liste von Tokens dann aus dem Text herausfiltern.\n",
    "\n",
    "Liste von Stoppwörtern erstellen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'some', 'been', 'as', 'haven', 'so', 'while', 'hadn', 'whom', 'hasn', 'until', 'above', 'very', 'we', \"that'll\", 'when', 're', 'and', 'all', 'are', 'who', 'couldn', 'up', 'more', 'shan', \"it's\", 'what', 'ourselves', 'down', 'which', 'can', \"doesn't\", 'it', 'do', 'be', 'own', \"mustn't\", \"should've\", \"wasn't\", 'ma', 'him', \"didn't\", 'y', 'nor', 'below', 'themselves', 'no', 'under', 'once', 'were', 'that', 'herself', 'because', 'd', \"shan't\", 'against', 'such', 'off', \"couldn't\", 'was', 'here', 'but', 'its', 'didn', \"you're\", 'theirs', 'to', 'a', 'than', 'an', 'doesn', \"weren't\", \"needn't\", 'won', 'over', 'why', 'ours', 'during', \"hadn't\", 'for', 'from', \"shouldn't\", 'most', 'wouldn', 'myself', 'in', 'isn', 't', 'your', \"you've\", 'or', 'i', 'now', \"aren't\", 'our', 'she', 'yours', 'have', 'if', 'his', 've', 'there', 'only', \"you'll\", 'doing', 'again', 'is', 'weren', 'before', 'has', 'll', 'these', 'those', \"haven't\", 'ain', 'just', \"she's\", 'did', 'then', 'aren', 'wasn', 'each', 'does', \"mightn't\", 'how', 'they', 'he', \"don't\", 'her', 'shouldn', 'the', 'am', 'same', 'of', \"you'd\", 'after', 'will', 'both', 'other', 'out', 'further', 's', 'yourselves', \"hasn't\", 'not', 'o', 'into', 'mustn', 'himself', 'needn', 'having', 'too', 'with', 'yourself', 'any', 'by', 'their', 'should', 'few', 'had', \"won't\", \"wouldn't\", 'between', 'don', 'this', 'where', 'me', \"isn't\", 'my', 'on', 'm', 'being', 'mightn', 'itself', 'them', 'through', 'about', 'you', 'hers', 'at'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stoppwörter herausfiltern: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['As', 'you', 'yourself', 'are', 'changing', 'you', 'may', 'also', 'begin', 'to', 'change', 'the', 'way', 'you', 'spend', 'your', 'time', '.', 'Instead', 'of', 'spending', 'four', 'hours', 'each', 'day', 'watching', 'television', ',', 'you', 'may', 'now', 'prefer', 'to', 'play', 'the', 'saxophone', 'in', 'a', 'jazz', 'band', 'and', 'to', 'have', 'fun', 'working', 'on', 'your', 'first', 'novel', '.', 'Instead', 'of', 'spending', 'the', 'weekends', 'hanging', 'out', 'in', 'the', 'pub', 'with', 'your', 'old', 'buddies', 'talking', 'about', 'football', ',', 'you', 'acquire', 'new', 'friends', 'with', 'whom', 'you', 'can', 'discuss', 'things', 'that', 'now', 'seem', 'to', 'you', 'to', 'be', 'of', 'greater', 'significance', 'than', 'sport', '.', 'Together', 'with', 'some', 'of', 'these', 'new', 'friends', ',', 'you', 'set', 'up', 'a', 'local', 'chapter', 'of', 'an', 'international', 'non-', 'profit', 'to', 'help', 'draw', 'attention', 'to', 'the', 'plight', 'of', 'political', 'prisoners', '.'] \n",
      "\n",
      "Filterd Sentence: ['As', 'changing', 'may', 'also', 'begin', 'change', 'way', 'spend', 'time', '.', 'Instead', 'spending', 'four', 'hours', 'day', 'watching', 'television', ',', 'may', 'prefer', 'play', 'saxophone', 'jazz', 'band', 'fun', 'working', 'first', 'novel', '.', 'Instead', 'spending', 'weekends', 'hanging', 'pub', 'old', 'buddies', 'talking', 'football', ',', 'acquire', 'new', 'friends', 'discuss', 'things', 'seem', 'greater', 'significance', 'sport', '.', 'Together', 'new', 'friends', ',', 'set', 'local', 'chapter', 'international', 'non-', 'profit', 'help', 'draw', 'attention', 'plight', 'political', 'prisoners', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_sent=[]\n",
    "\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "\n",
    "print(\"Tokenized Sentence:\",tokenized_word, \"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Die Lexikon-Normierung berücksichtigt eine andere Art von Rauschen im Text. Zum Beispiel, `Verbindung, verbunden, verbinden` reduzieren auf ein gemeinsames Wort `verbinden`. Es reduziert ableitungsbedingte Formen eines Wortes auf ein gemeinsames Wurzelwort.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming** ist ein Prozess der linguistischen Normalisierung, der Wörter auf ihr Wortstamm-Wort reduziert oder die abgeleitete Affixe abhackt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Sentence: ['As', 'chang', 'may', 'also', 'begin', 'chang', 'way', 'spend', 'time', '.', 'instead', 'spend', 'four', 'hour', 'day', 'watch', 'televis', ',', 'may', 'prefer', 'play', 'saxophon', 'jazz', 'band', 'fun', 'work', 'first', 'novel', '.', 'instead', 'spend', 'weekend', 'hang', 'pub', 'old', 'buddi', 'talk', 'footbal', ',', 'acquir', 'new', 'friend', 'discuss', 'thing', 'seem', 'greater', 'signific', 'sport', '.', 'togeth', 'new', 'friend', ',', 'set', 'local', 'chapter', 'intern', 'non-', 'profit', 'help', 'draw', 'attent', 'plight', 'polit', 'prison', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed_words=[]\n",
    "\n",
    "for w in filtered_sent:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "\n",
    "#print(\"Filtered Sentence:\",filtered_sent)\n",
    "print(\"Stemmed Sentence:\",stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Sentence: ['As', 'changing', 'may', 'also', 'begin', 'change', 'way', 'spend', 'time', '.', 'Instead', 'spending', 'four', 'hour', 'day', 'watching', 'television', ',', 'may', 'prefer', 'play', 'saxophone', 'jazz', 'band', 'fun', 'working', 'first', 'novel', '.', 'Instead', 'spending', 'weekend', 'hanging', 'pub', 'old', 'buddy', 'talking', 'football', ',', 'acquire', 'new', 'friend', 'discus', 'thing', 'seem', 'greater', 'significance', 'sport', '.', 'Together', 'new', 'friend', ',', 'set', 'local', 'chapter', 'international', 'non-', 'profit', 'help', 'draw', 'attention', 'plight', 'political', 'prisoner', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#ps = PorterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "lemmatized_words=[]\n",
    "\n",
    "for w in filtered_sent:\n",
    "    lemmatized_words.append(lem.lemmatize(w))\n",
    "\n",
    "#print(\"Filtered Sentence:\",filtered_sent)\n",
    "print(\"Stemmed Sentence:\",lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Lemmatisierung** reduziert Wörter auf ihr Ausgangswort, das sprachlich korrekte Lemmata sind. Es transformiert das Wurzelwort mit Hilfe von Wortschatz und morphologischer Analyse. Die Lemmatisierung ist in der Regel ausgeklügelter als das Stemming. Ein Stemmer arbeitet an einem einzelnen Wort, ohne den Kontext zu kennen. Zum Beispiel hat das Wort \"besser\" \"gut\" als seine Lemma. Diese Sache wird beim Stemming fehlen, da sie ein Nachschlagen des Dictionary erfordert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Word: fly\n",
      "Stemmed Word: fli\n"
     ]
    }
   ],
   "source": [
    "#performing stemming and Lemmatization als Beispiel\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "\n",
    "word = \"flying\"\n",
    "print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n",
    "print(\"Stemmed Word:\",stem.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Hauptziel von **Part-of-Speech(POS)-Tagging** ist die Identifizierung der grammatikalischen Gruppe eines bestimmten Wortes. Ob es sich um ein NOUN, PRONOUN, ADJECTIVE, VERB, ADVERBS, etc. handelt, basierend auf dem Kontext. POS Tagging sucht nach Beziehungen innerhalb des Satzes und weist dem Wort einen entsprechenden `Tag` zu.\n",
    "\n",
    "sehen wir uns die Wortarten nach der Penn Treebank-Stadandards Tabelle an:\n",
    "* VB = Verb Basisform\n",
    "* NN = Nomen im Singular\n",
    "* DT = Artikel\n",
    "* JJ = Adjektiv\n",
    "* PRP = Personalpronom\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('As', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('yourself', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('changing', 'VBG'),\n",
       " ('you', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('begin', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('change', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('spend', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('time', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Instead', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('spending', 'VBG'),\n",
       " ('four', 'CD'),\n",
       " ('hours', 'NNS'),\n",
       " ('each', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('watching', 'VBG'),\n",
       " ('television', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('now', 'RB'),\n",
       " ('prefer', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('play', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('saxophone', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('jazz', 'NN'),\n",
       " ('band', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('fun', 'NN'),\n",
       " ('working', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('novel', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Instead', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('spending', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('weekends', 'NNS'),\n",
       " ('hanging', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pub', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('old', 'JJ'),\n",
       " ('buddies', 'NNS'),\n",
       " ('talking', 'VBG'),\n",
       " ('about', 'IN'),\n",
       " ('football', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('acquire', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('whom', 'WP'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('discuss', 'VB'),\n",
       " ('things', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('now', 'RB'),\n",
       " ('seem', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('you', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('of', 'IN'),\n",
       " ('greater', 'JJR'),\n",
       " ('significance', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('sport', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Together', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('friends', 'NNS'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('set', 'VBP'),\n",
       " ('up', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('local', 'JJ'),\n",
       " ('chapter', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('international', 'JJ'),\n",
       " ('non-', 'JJ'),\n",
       " ('profit', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('help', 'VB'),\n",
       " ('draw', 'VB'),\n",
       " ('attention', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('plight', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " ('prisoners', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokenized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized word:  ['@', 'lindner', 'lol', ',', 'that', 'was', '#', 'awesome', ':', ')'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet = \"@lindner lol, that was #awesome :)\"\n",
    "tokened_W=word_tokenize(tweet, language='english')\n",
    "print(\"tokenized word: \", tokened_W, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es gibt verschieden Arten von Tokenizern...\n",
    "\n",
    "laden wir unseren `@lindner lol, that was #awesome :)` in das Textfeld auf folgender Page:\n",
    "\n",
    "https://text-processing.com/demo/tokenize/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see: https://exmediawiki.khm.de/exmediawiki/index.php/Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@lindner', 'lol,', 'that', 'was', '#awesome', ':)'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tweet.split(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
