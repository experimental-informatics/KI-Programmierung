{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding GAN's: https://medium.com/datadriveninvestor/deep-learning-generative-adversarial-network-gan-34abb43c0644\n",
    "\n",
    "![](https://miro.medium.com/max/2176/1*t78gwhhw-hn1CgXc1K89wA.png)\n",
    "\n",
    "Das Ziel des Generators ist es, Daten zu generieren, die den Trainingsdaten sehr ähnlich sind. \n",
    "\n",
    "Vom Generator generierte Daten sollten nicht von den tatsächlichen Daten zu unterscheiden sein.\n",
    "\n",
    "\n",
    "Diskriminator verwendet zwei Sätze von Eingaben, \n",
    "- eine Eingabe stammt aus dem Trainingsdatensatz (Realdaten) \n",
    "- und die andere Eingabe ist der vom Generator generierte Datensatz.\n",
    "\n",
    "GAN verwendet die MNIST-Daten und identifiziert die latente Merkmalsdarstellung zum Erzeugen von Ziffern. \n",
    "\n",
    "Am Ende werden wir sehen, wie die Generatoren echt aussehende MNIST-Ziffern erzeugen können.\n",
    "\n",
    "## Importieren wir die benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten aus dem Mnist-Datensatz. \n",
    "Wir erstellen eine Funktion load_data () Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    # konvertieren der Shape von x_train von (60000, 28, 28) zu (60000, 784) \n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "(X_train, y_train,X_test, y_test)=load_data()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimizer\n",
    "Wir werden den Adam-Optimierer verwenden, da dieser recheneffizient ist und nur sehr wenig Speicher benötigt. \n",
    "\n",
    "Adam ist eine Kombination aus Adagrad und RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der GAN-Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1134/1*Sqhji7Zz4IK2HDgCOabhXQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen des Generators\n",
    "Wir erstellen einen Generator, aus Dense-Layern die durch `tanh` aktiviert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    generator=Sequential()\n",
    "    generator.add(Dense(units=256,input_dim=100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=1024))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=784, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
    "    return generator\n",
    "g=create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen des Diskriminators\n",
    "Wir erstellen jetzt den Diskriminator aus Dense-Layern.\n",
    "\n",
    "Der Diskriminator nimmt die Eingabe von den _realen_ Daten der Größe 784 und auch die vom Generator erzeugten Bilder auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    discriminator=Sequential()\n",
    "    discriminator.add(Dense(units=1024,input_dim=784))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "    discriminator.add(Dense(units=512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
    "    return discriminator\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen des GAN\n",
    "Wir erstellen jetzt das GAN, in der wir den Generator und den Diskriminator kombinieren. \n",
    "\n",
    "Wenn wir den Generator trainieren, werden wir den Diskriminator einfrieren.\n",
    "\n",
    "Wir geben das verrauschte Bild mit einer Form von 100 Einheiten in den Generator ein. \n",
    "\n",
    "Das vom Generator erzeugte Ausgangssignal wird dem Diskriminator zugeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 784)               1486352   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 1460225   \n",
      "=================================================================\n",
      "Total params: 2,946,577\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 1,460,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generierte Bilder zeichnen & speichern\n",
    "Bevor wir mit dem Training des Modells beginnen, schreiben wir eine Funktion `plot_generated_images`, um die generierten Bilder zu zeichnen. \n",
    "\n",
    "Auf diese Weise können wir sehen, wie die Bilder erzeugt werden. \n",
    "\n",
    "Wir speichern die generierten Bilder in einer Datei, die wir später anzeigen können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(100,28,28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan_generated_image %d.png' %epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## disable scrollable frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    \n",
    "    #Laden Sie die Daten aus dem mnist-Datensatz\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Erstellen des GANs mit Generator und Diskriminator. \n",
    "    ## Zuerst wird das neuronale Netzwerk für Generator und Diskriminator erstellt\n",
    "    generator= create_generator()\n",
    "    discriminator= create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    # Für jede Epoche verwenden wir tqdm , damit unsere Loops eine \n",
    "    ## intelligente Fortschrittsanzeige darstellen. \n",
    "    for e in range(1,epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for _ in tqdm(range(batch_size)):\n",
    "            # Wir erzeugen zufälliges Rauschen, um den Generator zu initialisieren.\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            # Der Generator generiert dann gefälschte MNIST-Ziffern aus dem gestörten Eingang.\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            \n",
    "            # Wir müssen nun einen Datenstapel erstellen, der gefälschte Bilder vom Generator und\n",
    "            # echte Bilder aus der MNIST-Datenbank erhält\n",
    "            # um diese dann an den Diskriminator weiterzuleiten\n",
    "            \n",
    "            # ein Set aus zufälligen MNIST-Bildern holen\n",
    "            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            # Eine Folge von Arrays erstellen mit `concatenante` aus den Sets realer und fake bilder \n",
    "            X= np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            # Zielvariablen für echte und gefälschte Bilder erstellen\n",
    "            y_dis=np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            \n",
    "            # Wir trainieren den Diskriminator vor dem Starten der GAN mit einigen gefälschten und echten Daten. \n",
    "            \n",
    "            # Auf diese Weise können wir überprüfen, ob unsere kompilierten Modelle \n",
    "            ## sowohl mit unseren Realdaten als auch mit den verrauschten Daten einwandfrei funktionieren.\n",
    "            \n",
    "            #Pretraining\n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking < wir nehmen den noised input des Generators und verkaufen diesen als echtes bild\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            \n",
    "            # Wenn wir die GAN trainieren, müssen wir die Gewichte des Diskriminators einfrieren. \n",
    "            ## Wir tun dies mit der `trainable flag`\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            \n",
    "            # Das GAN wird durch abwechselndes Training des Diskriminators \n",
    "            ## und anschließendes Training des verketteten GAN-Modells mit eingefrorenen \n",
    "            ## Diskriminatorgewichten trainiert            \n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "        \n",
    "        # Für jeweils 20 Epochen zeichnen wir die erzeugten Bilder            \n",
    "        if e == 1 or e % 20 == 0:\n",
    "           \n",
    "            plot_generated_images(e, generator)\n",
    "training(400,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## possible output:\n",
    "![](https://miro.medium.com/max/2440/1*xm6_ZfvfKSHe2KS49DT8TQ.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
